{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a19fe0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39ae2ba",
   "metadata": {},
   "source": [
    "# 1 Memuat Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "747725e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine()\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "890e96ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  target  \n",
       "0                            3.92   1065.0       0  \n",
       "1                            3.40   1050.0       0  \n",
       "2                            3.17   1185.0       0  \n",
       "3                            3.45   1480.0       0  \n",
       "4                            2.93    735.0       0  \n",
       "..                            ...      ...     ...  \n",
       "173                          1.74    740.0       2  \n",
       "174                          1.56    750.0       2  \n",
       "175                          1.56    835.0       2  \n",
       "176                          1.62    840.0       2  \n",
       "177                          1.60    560.0       2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mengubah menjadi DataFrame untuk analisis yang lebih mudah\n",
    "df = pd.DataFrame(X, columns=data.feature_names)\n",
    "df['target'] = y\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8ab5c7",
   "metadata": {},
   "source": [
    "Dataset ini memiliki 178 baris dan 13 kolom fitur independen serta satu kolom dependen (target). Masih ingatkah tahapan terakhir persiapan data sebelum melatih model? Yup! Anda perlu membagi dataset menjadi data latih dan data uji. Pada kasus ini, kita akan membagi ukuran dataset menjadi 80% data uji dan 20% data latih. Silakan eksplorasi mandiri untuk proporsi lainnya ya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3b0f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# membagi data'\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4818b8c0",
   "metadata": {},
   "source": [
    "# 2. Filter Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb3749d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitur yang dipilih dengan Filter Method (SelectKBest):\n",
      "[ 9 12]\n"
     ]
    }
   ],
   "source": [
    "# Menggunakan SelectKBest untuk memilih fitur terbaik\n",
    "filter_selector = SelectKBest(score_func=chi2, k=2) # memulih 2 fitur terbaik\n",
    "X_train_filter = filter_selector.fit_transform(X_train, y_train)\n",
    "X_test_filter = filter_selector.transform(X_test)\n",
    "\n",
    "print(\"fitur yang dipilih dengan Filter Method (SelectKBest):\")\n",
    "print(filter_selector.get_support(indices=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6114db0f",
   "metadata": {},
   "source": [
    "SelectKBest\n",
    "- SelectKBest adalah salah satu metode dari filter methods yang umum digunakan untuk memilih fitur terbaik berdasarkan skor statistik tertentu.\n",
    "\n",
    "  - Parameter score_func=chi2 berarti metode ini menggunakan Chi-squared (χ²) sebagai fungsi skor. Chi-squared adalah metode uji statistik yang digunakan untuk mengukur independensi antara dua variabel kategorikal.\n",
    "  - Parameter k=2 artinya kita hanya akan memilih 2 fitur terbaik dari semua fitur yang ada di dataset. Dengan kata lain, ini akan menyeleksi dua fitur dengan skor tertinggi berdasarkan hasil uji Chi-squared.\n",
    "\n",
    "  Kedua parameter ini bisa Anda sesuaikan dengan studi kasus dan trial and error ya. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec112178",
   "metadata": {},
   "source": [
    "- fit_transform(X_train, y_train)\n",
    "  - fit(X_train, y_train) merupakan metode yang akan menghitung skor Chi-squared untuk setiap fitur pada data pelatihan (X_train) terhadap target (y_train).\n",
    "  - transform(X_train) merupakan fungsi yang bertugas untuk menyalin data dari X_train, tetapi pada kasus ini hanya memiliki fitur yang tersimpan pada filter_selector.\n",
    "\n",
    "Hasilnya adalah sebuah dataset pelatihan baru (X_train_filter) yang hanya mengandung dua fitur terbaik hasil perhitungan Chi-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1803f7",
   "metadata": {},
   "source": [
    "- transform(X_test)\n",
    "Fungsi transform(X_test) digunakan untuk mentransformasikan dataset uji (X_test) dengan memilih fitur yang sama yang dipilih dari dataset pelatihan.\n",
    "- get_support(indices=True)\n",
    "Fungsi get_support(indices=True) digunakan untuk mendapatkan indeks dari fitur-fitur yang dipilih. Dalam hal ini, fitur yang dipilih adalah dua fitur dengan skor tertinggi berdasarkan uji Chi-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6d3c14",
   "metadata": {},
   "source": [
    "Fungsi ini akan mencetak indeks fitur yang dipilih dari dataset awal yang bisa digunakan untuk memahami fitur mana yang dipertahankan setelah proses seleksi. Sehingga, output akhir dari kode ini merupakan dataset yang sudah difilter dan informasi angka indeks dari fitur yang dipilih."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f047ac9f",
   "metadata": {},
   "source": [
    "Sampai di sini, Anda sudah memiliki sebuah dataset yang terdiri dari dua buah fitur dengan skor independensi paling besar. Tahan sejenak rasa ingin tahu Anda, karena pada akhir materi ini kita akan membandingkan performa dari ketiga metode feature selection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a17cca",
   "metadata": {},
   "source": [
    "# 3. Wrapper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9a893aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitur yang dipilih dengan Wrapper Method (RFE):\n",
      "[0 6]\n"
     ]
    }
   ],
   "source": [
    "# Menggunakan RFE (Recursive Feature Elimination) dengan Logistic Regression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=5000)\n",
    "rfe_selector = RFE(model, n_features_to_select=2) # memilih 2 fitur terbaik\n",
    "X_train_rfe = rfe_selector.fit_transform(X_train, y_train)\n",
    "X_test_rfe = rfe_selector.transform(X_test)\n",
    "\n",
    "print(\"fitur yang dipilih dengan Wrapper Method (RFE):\")\n",
    "print(rfe_selector.get_support(indices=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab1d7a1",
   "metadata": {},
   "source": [
    "Mirip dengan filter methods pada materi sebelumnya, kode di atas akan mencari dua buah fitur yang paling relevan berdasarkan perhitungan Recursive Feature Elimination. Namun, metode ini menghasilkan indeks fitur yang berbeda jika kita bandingkan dengan filter methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989b3dba",
   "metadata": {},
   "source": [
    "Mengapa hal ini bisa terjadi? Tenang saja ini merupakan hal yang wajar, perbedaan ini disebabkan kedua metode ini menggunakan perhitungan matematis yang berbeda. Chi2 akan mengukur hubungan antara fitur dan target secara independen tanpa menggunakan model pembelajaran mesin dan tidak mempertimbangkan interaksi antar fitur. Lalu, RFE akan menghitung menggunakan model machine learning dan secara iteratif memilih fitur terbaik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd1d506",
   "metadata": {},
   "source": [
    "# 4. Embedded Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d57d48de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitur yang dipilih dengan Embedded Methods (di atas ambang batas):\n",
      "alcohol: 0.11239773542143086\n",
      "flavanoids: 0.20229341635663622\n",
      "color_intensity: 0.1712021830864957\n",
      "hue: 0.07089132259413944\n",
      "od280/od315_of_diluted_wines: 0.1115643167260497\n",
      "proline: 0.13904586955351153\n",
      "\n",
      "Dimensi data pelatihan dengan fitur penting: (142, 6)\n",
      "Dimensi data pengujian dengan fitur penting: (36, 6)\n"
     ]
    }
   ],
   "source": [
    "# Menggunakan Random Forest untuk mendapatkan fitur penting\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    " \n",
    "# Mendapatkan fitur penting\n",
    "importances = rf_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    " \n",
    "# Menentukan ambang batas untuk fitur penting\n",
    "threshold = 0.05  # Misalnya, ambang batas 5%\n",
    "important_features_indices = [i for i in range(len(importances)) if importances[i] >= threshold]\n",
    " \n",
    "# Memindahkan fitur penting ke variabel baru\n",
    "X_important = X_train[:, important_features_indices]  # Hanya fitur penting dari data pelatihan\n",
    "X_test_important = X_test[:, important_features_indices]  # Hanya fitur penting dari data pengujian\n",
    " \n",
    "# Mencetak fitur yang dipilih\n",
    "print(\"Fitur yang dipilih dengan Embedded Methods (di atas ambang batas):\")\n",
    "for i in important_features_indices:\n",
    "    print(f\"{data.feature_names[i]}: {importances[i]}\")\n",
    "\n",
    "# X_important sekarang berisi hanya fitur penting\n",
    "print(\"\\nDimensi data pelatihan dengan fitur penting:\", X_important.shape)\n",
    "print(\"Dimensi data pengujian dengan fitur penting:\", X_test_important.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce15c4da",
   "metadata": {},
   "source": [
    "Secara garis besar, kode di atas akan menjalankan beberapa langkah hingga akhirnya mendapatkan fitur yang paling relevan menurut perhitungannya.\n",
    "\n",
    "Setelah model dilatih, Anda bisa mendapatkan informasi tentang peran fitur menggunakan atribut feature_importances_. Nilai ini menunjukkan seberapa penting setiap fitur dalam membantu model membuat keputusan (pada kasus ini klasifikasi). Fitur dengan nilai feature_importance yang lebih tinggi memiliki pengaruh yang lebih besar terhadap prediksi model.\n",
    "\n",
    "Untuk menampilkan fitur terpenting, nilai feature_importance perlu diurutkan dari yang tertinggi ke terendah menggunakan np.argsort(importances)[::-1] sehingga Anda akan mendapatkan indeks fitur berdasarkan urutan kontribusinya.\n",
    "\n",
    "Selanjutnya, Anda perlu menetapkan ambang batas (threshold). Pada kasus ini, kita sepakat menentukan nilai sebesar 0.05 yang artinya kita hanya akan mempertahankan fitur yang memiliki nilai kepentingan di atas 5%. Bagaimana caranya memilih fiturnya? Tugas ini akan dieksekusi oleh baris kode [i for i in range(len(importances)) if importances[i] >= threshold] yang bertugas untuk memilih indeks fitur yang memenuhi kriteria tersebut.\n",
    "\n",
    "Setelah fitur-fitur penting dipilih, Anda perlu memindahkan data yang berisikan fitur yang dianggap penting ke dalam variabel baru. X_important adalah versi dari X_train yang hanya berisi fitur-fitur yang dianggap penting, dan hal yang sama dilakukan untuk data pengujian (X_test_important).\n",
    "\n",
    "Kode di atas juga mencetak daftar fitur yang dipilih beserta nilai kontribusinya sehingga kita bisa melihat fitur mana saja yang dianggap signifikan oleh model Random Forest. Terakhir, kode akan mencetak dimensi dari data pelatihan dan pengujian setelah seleksi fitur dengan tujuan memberikan gambaran tentang seberapa banyak fitur yang telah disaring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e0744c",
   "metadata": {},
   "source": [
    "# 5. Evaluasi Fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50da8684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi dengan fitur terpilih dari masing-masing metode\n",
    "def evaluate_model(X_train, X_test, y_train, y_test, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf0a6ab",
   "metadata": {},
   "source": [
    "Kode di atas merupakan sebuah fungsi yang akan melakukan pelatihan dan mendapatkan metriks evaluasi (accuracy) seperti yang sudah Anda biasa lakukan pada modul-modul sebelumnya, tetapi dibungkus pada sebuah fungsi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ce487a",
   "metadata": {},
   "source": [
    "Selanjutnya, mari kita latih model machine learning berdasarkan fitur yang telah ditentukan oleh masing-masing metode feature selection menggunakan kode berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45513cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Logistic Regression untuk Filter Methods\n",
    "logistic_model_filter = LogisticRegression(max_iter=200)\n",
    "accuracy_filter = evaluate_model(X_train_filter, X_test_filter, y_train, y_test, logistic_model_filter)\n",
    " \n",
    "# Model Logistic Regression untuk Wrapper Methods\n",
    "logistic_model_rfe = LogisticRegression(max_iter=200)\n",
    "accuracy_rfe = evaluate_model(X_train_rfe, X_test_rfe, y_train, y_test, logistic_model_rfe)\n",
    " \n",
    "# Model Random Forest untuk Embedded Methods\n",
    "accuracy_rf = evaluate_model(X_important, X_test_important, y_train, y_test, rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fa675f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Akurasi Model dengan Filter Methods: 0.89\n",
      "Akurasi Model dengan Wrapper Methods: 0.94\n",
      "Akurasi Model dengan Embedded Methods: 1.00\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nAkurasi Model dengan Filter Methods: {accuracy_filter:.2f}\")\n",
    "print(f\"Akurasi Model dengan Wrapper Methods: {accuracy_rfe:.2f}\")\n",
    "print(f\"Akurasi Model dengan Embedded Methods: {accuracy_rf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a05b6e",
   "metadata": {},
   "source": [
    "Seperti yang dapat Anda lihat masing-masing metode memiliki performa yang berbeda. Hal ini karena penggunaan fitur yang berbeda pada proses pelatihan model machine learning. Karena embedded methods memiliki akurasi sempurna, mungkin Anda berpikir “Ya sudah aku pakai embedded methods saja untuk semua kasus.” Eiitss, tidak semudah itu kawan, meskipun embedded methods bisa digunakan dalam berbagai skenario, tetapi tidak semua masalah cocok menggunakan metode ini. Ada beberapa hal yang menjadi pertimbangan ketika Anda akan melakukan feature selection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
